<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-08-01">

<title>WildTrax: an open platform for the management, storage, processing, sharing and discovery of avian data</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="wildtrax-ace-eco_files/libs/clipboard/clipboard.min.js"></script>
<script src="wildtrax-ace-eco_files/libs/quarto-html/quarto.js"></script>
<script src="wildtrax-ace-eco_files/libs/quarto-html/popper.min.js"></script>
<script src="wildtrax-ace-eco_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="wildtrax-ace-eco_files/libs/quarto-html/anchor.min.js"></script>
<link href="wildtrax-ace-eco_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="wildtrax-ace-eco_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="wildtrax-ace-eco_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="wildtrax-ace-eco_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="wildtrax-ace-eco_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#birds-as-ecological-indicators" id="toc-birds-as-ecological-indicators" class="nav-link" data-scroll-target="#birds-as-ecological-indicators">Birds as ecological indicators</a></li>
  <li><a href="#environmental-sensors-and-big-data" id="toc-environmental-sensors-and-big-data" class="nav-link" data-scroll-target="#environmental-sensors-and-big-data">Environmental sensors and big data</a></li>
  <li><a href="#collaborative-data-makes-collaborative-action" id="toc-collaborative-data-makes-collaborative-action" class="nav-link" data-scroll-target="#collaborative-data-makes-collaborative-action">Collaborative data makes collaborative action</a></li>
  </ul></li>
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods">Methods</a>
  <ul class="collapse">
  <li><a href="#database-infrastructure-and-design" id="toc-database-infrastructure-and-design" class="nav-link" data-scroll-target="#database-infrastructure-and-design">Database infrastructure and design</a></li>
  <li><a href="#front-end" id="toc-front-end" class="nav-link" data-scroll-target="#front-end">Front-end</a></li>
  <li><a href="#data-privacy-permissions-and-publication" id="toc-data-privacy-permissions-and-publication" class="nav-link" data-scroll-target="#data-privacy-permissions-and-publication">Data privacy, permissions and publication</a></li>
  <li><a href="#data-management-and-processing" id="toc-data-management-and-processing" class="nav-link" data-scroll-target="#data-management-and-processing">Data management and processing</a>
  <ul class="collapse">
  <li><a href="#acoustic-sensor" id="toc-acoustic-sensor" class="nav-link" data-scroll-target="#acoustic-sensor">Acoustic sensor</a></li>
  <li><a href="#camera-sensor" id="toc-camera-sensor" class="nav-link" data-scroll-target="#camera-sensor">Camera sensor</a></li>
  <li><a href="#point-counts" id="toc-point-counts" class="nav-link" data-scroll-target="#point-counts">Point counts</a></li>
  </ul></li>
  <li><a href="#analysis" id="toc-analysis" class="nav-link" data-scroll-target="#analysis">Analysis</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a>
  <ul class="collapse">
  <li><a href="#multiple-observers" id="toc-multiple-observers" class="nav-link" data-scroll-target="#multiple-observers">Multiple observers</a></li>
  <li><a href="#covariates" id="toc-covariates" class="nav-link" data-scroll-target="#covariates">Covariates</a></li>
  <li><a href="#artificial-intelligence-and-automated-classification" id="toc-artificial-intelligence-and-automated-classification" class="nav-link" data-scroll-target="#artificial-intelligence-and-automated-classification">Artificial intelligence and automated classification</a></li>
  <li><a href="#impact-of-privacy-constrained-data-on-biological-metrics" id="toc-impact-of-privacy-constrained-data-on-biological-metrics" class="nav-link" data-scroll-target="#impact-of-privacy-constrained-data-on-biological-metrics">Impact of privacy-constrained data on biological metrics</a></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a></li>
  <li><a href="#acknowledgements" id="toc-acknowledgements" class="nav-link" data-scroll-target="#acknowledgements">Acknowledgements</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">WildTrax: an open platform for the management, storage, processing, sharing and discovery of avian data</h1>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="abstract" class="level1">
<h1>Abstract</h1>
<p>As environmental sensors become essential tools for monitoring and assessing bird population trends, their effective use relies on robust systems to manage the large datasets they generate. WildTrax (https://www.wildtrax.ca) is a web-based platform designed to manage, store, process, share, and discover environmental sensor data across local to international scales. By enabling researchers to address ecological questions ranging from fine to broad scales through novel analytical approaches, WildTrax strengthens the avian data network, fosters collaboration, and enhances data sharing to support bird conservation efforts in Canada.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<section id="birds-as-ecological-indicators" class="level2">
<h2 class="anchored" data-anchor-id="birds-as-ecological-indicators">Birds as ecological indicators</h2>
<p>Birds have long been recognized as reliable ecological indicators due to their sensitivity to environmental changes, broad distribution across ecosystems, and measurable population dynamics. They can signal shifts in ecosystem health, function, and biodiversity, providing critical insights for conservation and management. Birds are also valuable indicators because they occupy diverse niches, have well-studied life histories, and often correlate with the health of other taxa (<span class="citation" data-cites="fleishman2005using">Fleishman et al. (<a href="#ref-fleishman2005using" role="doc-biblioref">2005</a>)</span>). Their utility spans ecosystem monitoring, habitat quality assessment, and gauging the impact of environmental stressors such as land use change, climate change, and pollution (<span class="citation" data-cites="niemi1997critical">Niemi et al. (<a href="#ref-niemi1997critical" role="doc-biblioref">1997</a>)</span>, <span class="citation" data-cites="mekonen2017birds">Mekonen (<a href="#ref-mekonen2017birds" role="doc-biblioref">2017</a>)</span>). Advances in statistical modeling now allow for better integration of uncertainty, phylogenetic relationships, and temporal autocorrelation, enhancing the reliability of bird-based indicators (<span class="citation" data-cites="fraixedas2020state">Fraixedas et al. (<a href="#ref-fraixedas2020state" role="doc-biblioref">2020</a>)</span>). However, there remains challenges in their application as indicators, including spatial, seasonal, and habitat biases, as well as insufficient consideration of statistical uncertainty and temporal autocorrelation in multi-species bird indicators (<span class="citation" data-cites="gregory2003using">Gregory et al. (<a href="#ref-gregory2003using" role="doc-biblioref">2003</a>)</span>, <span class="citation" data-cites="fraixedas2020state">Fraixedas et al. (<a href="#ref-fraixedas2020state" role="doc-biblioref">2020</a>)</span>). Addressing these gaps is crucial for improving their efficacy in informing Canada’s commitments under the Global Biodiversity Framework.</p>
<p>Avian surveys rely on skilled observers to accurately identify and count birds by sight or sound. Point count surveys incorporate distance and time-interval sampling to adjust for detectability, yielding estimates of population size or density critical for conservation decisions (<span class="citation" data-cites="gregory2003using">Gregory et al. (<a href="#ref-gregory2003using" role="doc-biblioref">2003</a>)</span>; <span class="citation" data-cites="fraixedas2020state">Fraixedas et al. (<a href="#ref-fraixedas2020state" role="doc-biblioref">2020</a>)</span>; <span class="citation" data-cites="mekonen2017birds">Mekonen (<a href="#ref-mekonen2017birds" role="doc-biblioref">2017</a>)</span>; <span class="citation" data-cites="niemi1997critical">Niemi et al. (<a href="#ref-niemi1997critical" role="doc-biblioref">1997</a>)</span>; <span class="citation" data-cites="fleishman2005using">Fleishman et al. (<a href="#ref-fleishman2005using" role="doc-biblioref">2005</a>)</span>; <span class="citation" data-cites="quinn2011application">Quinn et al. (<a href="#ref-quinn2011application" role="doc-biblioref">2011</a>)</span>; <span class="citation" data-cites="bock1984birds">Bock and Webb (<a href="#ref-bock1984birds" role="doc-biblioref">1984</a>)</span>). However, observer bias and error remain persistent issues in multi-observer programs (<span class="citation" data-cites="faamesbystrark1981">(<a href="#ref-faamesbystrark1981" role="doc-biblioref"><strong>faamesbystrark1981?</strong></a>)</span>; <span class="citation" data-cites="keplerscott1981">(<a href="#ref-keplerscott1981" role="doc-biblioref"><strong>keplerscott1981?</strong></a>)</span>). While many programs mitigate this through standardized methods and experienced observers, long-term datasets like the Breeding Bird Survey (BBS) rarely account for within-observer error beyond first-year learning effects (<span class="citation" data-cites="kendall1996">(<a href="#ref-kendall1996" role="doc-biblioref"><strong>kendall1996?</strong></a>)</span>; <span class="citation" data-cites="linkandsauer2004">(<a href="#ref-linkandsauer2004" role="doc-biblioref"><strong>linkandsauer2004?</strong></a>)</span>; <span class="citation" data-cites="farmer2014">(<a href="#ref-farmer2014" role="doc-biblioref"><strong>farmer2014?</strong></a>)</span>).</p>
<p>The adoption of autonomous recording units (ARUs) has allowed single-visit human surveys to be supplemented or replaced with archived acoustic recordings, enabling “big data” approaches that integrate multiple datasets for broader ecological inference (<span class="citation" data-cites="hampton2013big">Hampton et al. (<a href="#ref-hampton2013big" role="doc-biblioref">2013</a>)</span>; <span class="citation" data-cites="farley2018situating">Farley et al. (<a href="#ref-farley2018situating" role="doc-biblioref">2018</a>)</span>; <span class="citation" data-cites="shin2015ecological">Shin and Choi (<a href="#ref-shin2015ecological" role="doc-biblioref">2015</a>)</span>; <span class="citation" data-cites="nathan2022big">Nathan et al. (<a href="#ref-nathan2022big" role="doc-biblioref">2022</a>)</span>; <span class="citation" data-cites="peters2014harnessing">Peters et al. (<a href="#ref-peters2014harnessing" role="doc-biblioref">2014</a>)</span>; <span class="citation" data-cites="hallgren2016biodiversity">Hallgren et al. (<a href="#ref-hallgren2016biodiversity" role="doc-biblioref">2016</a>)</span>). Detection rates depend on factors such as distance, frequency range, and habitat (<span class="citation" data-cites="yip2017">(<a href="#ref-yip2017" role="doc-biblioref"><strong>yip2017?</strong></a>)</span>). ARUs improve data quality through permanent records and reproducible analyses, supporting integration with traditional datasets and advancing broader conservation goals (<span class="citation" data-cites="fox2017generating">Fox et al. (<a href="#ref-fox2017generating" role="doc-biblioref">2017</a>)</span>; <span class="citation" data-cites="stephenson2020inventory">Stephenson and Stengel (<a href="#ref-stephenson2020inventory" role="doc-biblioref">2020</a>)</span>; <span class="citation" data-cites="buxton2021key">Buxton et al. (<a href="#ref-buxton2021key" role="doc-biblioref">2021</a>)</span>).</p>
<p>Both human observers and machine learning classifiers introduce detection errors, including false positives (FP) and false negatives (FN), which can skew population inferences, particularly for rare species (<span class="citation" data-cites="campbellfrancis2011">(<a href="#ref-campbellfrancis2011" role="doc-biblioref"><strong>campbellfrancis2011?</strong></a>)</span>; <span class="citation" data-cites="miller2015">(<a href="#ref-miller2015" role="doc-biblioref"><strong>miller2015?</strong></a>)</span>; <span class="citation" data-cites="clement2022">(<a href="#ref-clement2022" role="doc-biblioref"><strong>clement2022?</strong></a>)</span>). Observer variability in detection and identification further complicates multi-source datasets (<span class="citation" data-cites="gregory2003using">Gregory et al. (<a href="#ref-gregory2003using" role="doc-biblioref">2003</a>)</span>; <span class="citation" data-cites="fraixedas2020state">Fraixedas et al. (<a href="#ref-fraixedas2020state" role="doc-biblioref">2020</a>)</span>). Yet, FP and FN rates are rarely reported, creating the false impression of flawless data. Comparable fields, such as botany, emphasize training and calibration to reduce error (<span class="citation" data-cites="morrison2016">(<a href="#ref-morrison2016" role="doc-biblioref"><strong>morrison2016?</strong></a>)</span>; <span class="citation" data-cites="dennetnielsen2019">(<a href="#ref-dennetnielsen2019" role="doc-biblioref"><strong>dennetnielsen2019?</strong></a>)</span>), but these approaches are challenging to implement for mobile taxa like birds. Re-reviewing acoustic data offers a means to assess and correct error (<span class="citation" data-cites="golding2016">(<a href="#ref-golding2016" role="doc-biblioref"><strong>golding2016?</strong></a>)</span>; <span class="citation" data-cites="rempel2019">(<a href="#ref-rempel2019" role="doc-biblioref"><strong>rempel2019?</strong></a>)</span>). Additionally, the integration of diverse knowledge systems, including Indigenous Knowledge, can strengthen monitoring and error assessment efforts (<span class="citation" data-cites="jessen2022contributions">Jessen et al. (<a href="#ref-jessen2022contributions" role="doc-biblioref">2022</a>)</span>; <span class="citation" data-cites="lamb2023braiding">Lamb et al. (<a href="#ref-lamb2023braiding" role="doc-biblioref">2023</a>)</span>)</p>
</section>
<section id="environmental-sensors-and-big-data" class="level2">
<h2 class="anchored" data-anchor-id="environmental-sensors-and-big-data">Environmental sensors and big data</h2>
<p>Environmental sensors, such as autonomous recording units (ARUs) and remote camera traps, are reshaping avian monitoring by providing continuous, high-resolution, and large-scale data collection. These technologies mitigate many of the limitations inherent in traditional field surveys, offering reliable, replicable, and non-invasive methods for monitoring bird populations and their habitats, while providing a permanent record of the environment. ARUs are particularly effective for capturing vocalizations, enabling detailed identification and temporal analysis of species presence, abundance, and community dynamics over time (<span class="citation" data-cites="bock1984birds">Bock and Webb (<a href="#ref-bock1984birds" role="doc-biblioref">1984</a>)</span>). In an era where ecological science increasingly overlaps with the data-driven revolution, the integration of such sensors contributes to the accumulation of extensive datasets, often categorized as “big data” (<span class="citation" data-cites="hampton2013big">Hampton et al. (<a href="#ref-hampton2013big" role="doc-biblioref">2013</a>)</span>). These datasets, characterized by their volume, variety, veracity, and velocity, frequently exceed the capacities of traditional tools and demand innovative approaches for analysis (<span class="citation" data-cites="farley2018situating">Farley et al. (<a href="#ref-farley2018situating" role="doc-biblioref">2018</a>)</span>). Software applications and platforms exemplify the potential of centralized systems to standardize, integrate, and share these data, fostering interdisciplinary collaborations and enabling comprehensive insights into avian biodiversity patterns. The transformative power of environmental sensors lies in their ability to address biases and gaps in conventional monitoring while enabling advanced modeling techniques that incorporate temporal autocorrelation, spatial heterogeneity, and even phylogenetic relationships among species (<span class="citation" data-cites="peters2014harnessing">Peters et al. (<a href="#ref-peters2014harnessing" role="doc-biblioref">2014</a>)</span>). As the demand for scalable and timely ecological insights grows, so do the challenges of big data systems. Ensuring data quality, equitable access, and long-term preservation requires robust socio-technical frameworks, as emphasized by <span class="citation" data-cites="shin2015ecological">Shin and Choi (<a href="#ref-shin2015ecological" role="doc-biblioref">2015</a>)</span>. More recently, the computational demands of analyzing these large datasets has been interplexed with machine learning techniques and traditional ecological models. By integrating diverse datasets and harnessing the opportunities presented by big data, environmental sensors are poised to bridge the gap between raw ecological data and actionable conservation strategies. These tools not only enhance our ability to monitor and manage ecosystems but also contribute to the broader goal of ensuring ecological sustainability in an increasingly data-driven world (<span class="citation" data-cites="nathan2022big">Nathan et al. (<a href="#ref-nathan2022big" role="doc-biblioref">2022</a>)</span>).</p>
</section>
<section id="collaborative-data-makes-collaborative-action" class="level2">
<h2 class="anchored" data-anchor-id="collaborative-data-makes-collaborative-action">Collaborative data makes collaborative action</h2>
<p>Effectively leveraging birds as ecological indicators hinges on robust, collaborative, and accessible data management frameworks; this plays a pivotal role in this landscape by integrating environmental sensor data into a centralized system that bridges gaps across disciplines and scales. Software platforms that enable researchers and decision-makers to harmonize diverse datasets while ensuring consistency and quality in biodiversity monitoring efforts (<span class="citation" data-cites="stephenson2020inventory">Stephenson and Stengel (<a href="#ref-stephenson2020inventory" role="doc-biblioref">2020</a>)</span>). They can support advanced analyses for species- and community-level assessments, transforming raw environmental data into actionable insights that inform conservation strategies and policy development (<span class="citation" data-cites="fox2017generating">Fox et al. (<a href="#ref-fox2017generating" role="doc-biblioref">2017</a>)</span>). By addressing limitations in traditional methodologies and promoting data-sharing initiatives, open platforms contribute to a more cohesive understanding of ecological trends (<span class="citation" data-cites="buxton2021key">Buxton et al. (<a href="#ref-buxton2021key" role="doc-biblioref">2021</a>)</span>). Moreover, such systems foster collaboration among stakeholders, helping to align conservation priorities at regional, national, and even global scales (<span class="citation" data-cites="kartez2008information">Kartez and Casto (<a href="#ref-kartez2008information" role="doc-biblioref">2008</a>)</span>).</p>
<p>Here we present WildTrax, a platform for the storage, management, processing, sharing and discovery of environmental sensor data. Here we show examples of the WildTrax framework in action and . We also present ways to guide users on how WildTrax provides a standardized approach to quantifying and correcting FP, FN, and true negatives (TN) in avian datasets by enabling ARU data to be reviewed by multiple observers. We measure the extent of identification error and simulate its impacts on population estimates. Here, we offer a workflow for managing observer variability in ARU-based monitoring programs and outline the tools that WildTrax provides to support this process.</p>
</section>
</section>
<section id="methods" class="level1">
<h1>Methods</h1>
<section id="database-infrastructure-and-design" class="level2">
<h2 class="anchored" data-anchor-id="database-infrastructure-and-design">Database infrastructure and design</h2>
<p>WildTrax operates on PostgreSQL, a free and open-source relational database management system (version [insert version]) as its primary back-end. Postgres ensures optimized data and storage and management of complex biological data sets, including those metadata-rich records from media collected by ARUs and remote cameras. The application infrastructure is hosted on a virtualized server environment managed through…. The core system is distributed across virtual machines (VMs), each configured for specific roles, including application servers, database servers, and background processing nodes. These VMs are provisioned with specifications to support both daily user interactions and computationally intensive batch processes, such as audio and image file uploading and the execution of machine learning algorithms. Load balancing and redundancy measures are implemented to ensure platform availability, performance, and scalability. WildTrax supports standardized data schemas for biological monitoring, including autonomous recording units (ARUs), cameras, and point counts. This enables interoperability with external data repositories and analysis tools, such as machine learning workflows and environmental datasets (e.g., weather data). Media collected by environmental sensors are always linked hierarchically to their deployment location: the physical, geographic point defined by the ARU or camera. Sensors cannot exist independently of this parent location information. The live server is accessible at the University of Alberta, Edmonton, Canada, with optional storage services available on AWS S3 (https://aws.amazon.com/s3/storage-classes/glacier/). Back-ups are provided through AWS Deep Glacier.</p>
</section>
<section id="front-end" class="level2">
<h2 class="anchored" data-anchor-id="front-end">Front-end</h2>
<p>The front-end is a web-based user interface built using Vuejs (https://vuejs.org/) version 3, designed to provide intuitive access to data management tools, visualization dashboards, and analysis workflows using libraries such as PrimeVue (https://primevue.org/). The front-end Vue3 application is served via an Apache HTTP Server, which also routes API traffic through reverse proxy configurations to back-end services. User authentication and authorization are managed through role-based access control (RBAC) integrated via the Auth0 identity platform (https://auth0.com/). Auth0 supports both email and password authentication and federated identity providers, including Google OAuth, ensuring secure and flexible access pathways for a broad userbase. Access within WildTrax is structured hierarchically to reflect real-world data governance needs. The platform also integrates APIs for data exchange and offers export options in common scientific formats (e.g., CSV, JSON) to support downstream analysis in statistical or GIS software. Media files, such as audio recordings and images, are stored separately from the relational database but are indexed in PostgreSQL for efficient retrieval and linkage to their associated metadata and are stored in a FLAC lossless uncompressed format (<span class="citation" data-cites="macphail2015audio">(<a href="#ref-macphail2015audio" role="doc-biblioref"><strong>macphail2015audio?</strong></a>)</span>) with regular data storage savings of (30-40%).</p>
</section>
<section id="data-privacy-permissions-and-publication" class="level2">
<h2 class="anchored" data-anchor-id="data-privacy-permissions-and-publication">Data privacy, permissions and publication</h2>
<p>There are multiple levels of data privacy structure available throughout the system. Users are assigned roles at both the Organization (admin, read-only) and Project (admin, tagger, read-only) levels, enabling fine-grained permissions over data creation, editing, processing and sharing. This structure ensures that sensitive data sets can be securely managed within collaborative environments while maintaining transparency in data provenance and audit trails.</p>
<p>Publishing</p>
</section>
<section id="data-management-and-processing" class="level2">
<h2 class="anchored" data-anchor-id="data-management-and-processing">Data management and processing</h2>
<section id="acoustic-sensor" class="level3">
<h3 class="anchored" data-anchor-id="acoustic-sensor">Acoustic sensor</h3>
</section>
<section id="camera-sensor" class="level3">
<h3 class="anchored" data-anchor-id="camera-sensor">Camera sensor</h3>
<p>Camera users can therefore upload, process their image sets with AI, tag the remaining detail, conduct species verification</p>
</section>
<section id="point-counts" class="level3">
<h3 class="anchored" data-anchor-id="point-counts">Point counts</h3>
<p>The point count “sensor” serves as a repository for the Boreal Avian Modelling Centre’s (borealbirds.ca) point count data. Point counts are harmonized to a specific distance bands which methods are correspondent to ARU methods for synthesis.</p>
</section>
</section>
<section id="analysis" class="level2">
<h2 class="anchored" data-anchor-id="analysis">Analysis</h2>
<p>We ran an RDA on the differences between observers</p>
<p>We ran a AUC curve to highlight the differences between AI and species detections</p>
<p>Here we use the <code>wildrtrax</code> package (v 1.4) for our downstream analysis.</p>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<section id="multiple-observers" class="level2">
<h2 class="anchored" data-anchor-id="multiple-observers">Multiple observers</h2>
</section>
<section id="covariates" class="level2">
<h2 class="anchored" data-anchor-id="covariates">Covariates</h2>
<p>In summary, covariates that are easily integrated with the system.</p>
</section>
<section id="artificial-intelligence-and-automated-classification" class="level2">
<h2 class="anchored" data-anchor-id="artificial-intelligence-and-automated-classification">Artificial intelligence and automated classification</h2>
<p>In summary, AI results can be used as a tool to help users with their environmental sensor data tagging, but human-computer collaboration should always be frought with caution when analyzing results. The complacency of animal identification with AI proves to be a future challenge, disconnecting the ecologist from the species.</p>
</section>
<section id="impact-of-privacy-constrained-data-on-biological-metrics" class="level2">
<h2 class="anchored" data-anchor-id="impact-of-privacy-constrained-data-on-biological-metrics">Impact of privacy-constrained data on biological metrics</h2>
<p>In summary, increasingly public datasets will help improve modelling and biological metrics used in ecology.</p>
</section>
</section>
<section id="discussion" class="level1">
<h1>Discussion</h1>
<p>WildTrax will continue to be a leading force in shaping our environmental sensors use and distribute their data at global scale.</p>
</section>
<section id="acknowledgements" class="level1">
<h1>Acknowledgements</h1>
<p>We gratefully acknowledge the contributions of our collaborators and supporters, including</p>

</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-bock1984birds" class="csl-entry" role="listitem">
Bock, Carl E, and Betsy Webb. 1984. <span>“Birds as Grazing Indicator Species in Southeastern Arizona.”</span> <em>The Journal of Wildlife Management</em> 48 (3): 1045–49.
</div>
<div id="ref-buxton2021key" class="csl-entry" role="listitem">
Buxton, Rachel T, Joseph R Bennett, Andrea J Reid, Charles Shulman, Steven J Cooke, Charles M Francis, Elizabeth A Nyboer, et al. 2021. <span>“Key Information Needs to Move from Knowledge to Action for Biodiversity Conservation in Canada.”</span> <em>Biological Conservation</em> 256: 108983.
</div>
<div id="ref-farley2018situating" class="csl-entry" role="listitem">
Farley, Scott S, Andria Dawson, Simon J Goring, and John W Williams. 2018. <span>“Situating Ecology as a Big-Data Science: Current Advances, Challenges, and Solutions.”</span> <em>BioScience</em> 68 (8): 563–76.
</div>
<div id="ref-fleishman2005using" class="csl-entry" role="listitem">
Fleishman, Erica, James R Thomson, Ralph Mac Nally, Dennis D Murphy, and John P Fay. 2005. <span>“Using Indicator Species to Predict Species Richness of Multiple Taxonomic Groups.”</span> <em>Conservation Biology</em> 19 (4): 1125–37.
</div>
<div id="ref-fox2017generating" class="csl-entry" role="listitem">
Fox, Helen E, Megan D Barnes, Gabby N Ahmadia, Grace Kao, Louise Glew, Kelly Haisfield, Nur Ismu Hidayat, et al. 2017. <span>“Generating Actionable Data for Evidence-Based Conservation: The Global Center of Marine Biodiversity as a Case Study.”</span> <em>Biological Conservation</em> 210: 299–309.
</div>
<div id="ref-fraixedas2020state" class="csl-entry" role="listitem">
Fraixedas, Sara, Andreas Lindén, Markus Piha, Mar Cabeza, Richard Gregory, and Aleksi Lehikoinen. 2020. <span>“A State-of-the-Art Review on Birds as Indicators of Biodiversity: Advances, Challenges, and Future Directions.”</span> <em>Ecological Indicators</em> 118: 106728.
</div>
<div id="ref-gregory2003using" class="csl-entry" role="listitem">
Gregory, Richard D, David Noble, Rob Field, John Marchant, M Raven, and DW Gibbons. 2003. <span>“Using Birds as Indicators of Biodiversity.”</span> <em>Ornis Hungarica</em> 12 (13): 11–24.
</div>
<div id="ref-hallgren2016biodiversity" class="csl-entry" role="listitem">
Hallgren, Willow, Linda Beaumont, Andrew Bowness, Lynda Chambers, Erin Graham, Hamish Holewa, Shawn Laffan, et al. 2016. <span>“The Biodiversity and Climate Change Virtual Laboratory: Where Ecology Meets Big Data.”</span> <em>Environmental Modelling &amp; Software</em> 76: 182–86.
</div>
<div id="ref-hampton2013big" class="csl-entry" role="listitem">
Hampton, Stephanie E, Carly A Strasser, Joshua J Tewksbury, Wendy K Gram, Amber E Budden, Archer L Batcheller, Clifford S Duke, and John H Porter. 2013. <span>“Big Data and the Future of Ecology.”</span> <em>Frontiers in Ecology and the Environment</em> 11 (3): 156–62.
</div>
<div id="ref-jessen2022contributions" class="csl-entry" role="listitem">
Jessen, Tyler D, Natalie C Ban, Nicholas XEMŦOLTW Claxton, and Chris T Darimont. 2022. <span>“Contributions of Indigenous Knowledge to Ecological and Evolutionary Understanding.”</span> <em>Frontiers in Ecology and the Environment</em> 20 (2): 93–101.
</div>
<div id="ref-kartez2008information" class="csl-entry" role="listitem">
Kartez, Jack D, and Molly P Casto. 2008. <span>“Information into Action: Biodiversity Data Outreach and Municipal Land Conservation.”</span> <em>Journal of the American Planning Association</em> 74 (4): 467–80.
</div>
<div id="ref-lamb2023braiding" class="csl-entry" role="listitem">
Lamb, Clayton T, Roland Willson, Allyson K Menzies, Naomi Owens-Beek, Michael Price, Scott McNay, Sarah P Otto, et al. 2023. <span>“Braiding Indigenous Rights and Endangered Species Law.”</span> <em>Science</em> 380 (6646): 694–96.
</div>
<div id="ref-mekonen2017birds" class="csl-entry" role="listitem">
Mekonen, Sefi. 2017. <span>“Birds as Biodiversity and Environmental Indicator.”</span> <em>Indicator</em> 7 (21).
</div>
<div id="ref-nathan2022big" class="csl-entry" role="listitem">
Nathan, Ran, Christopher T Monk, Robert Arlinghaus, Timo Adam, Josep Alós, Michael Assaf, Henrik Baktoft, et al. 2022. <span>“Big-Data Approaches Lead to an Increased Understanding of the Ecology of Animal Movement.”</span> <em>Science</em> 375 (6582): eabg1780.
</div>
<div id="ref-niemi1997critical" class="csl-entry" role="listitem">
Niemi, Gerald J, Joann M Hanowski, Ann R Lima, Tom Nicholls, and Norm Weiland. 1997. <span>“A Critical Analysis on the Use of Indicator Species in Management.”</span> <em>The Journal of Wildlife Management</em>, 1240–52.
</div>
<div id="ref-peters2014harnessing" class="csl-entry" role="listitem">
Peters, Debra PC, Kris M Havstad, Judy Cushing, Craig Tweedie, Olac Fuentes, and Natalia Villanueva-Rosales. 2014. <span>“Harnessing the Power of Big Data: Infusing the Scientific Method with Machine Learning to Transform Ecology.”</span> <em>Ecosphere</em> 5 (6): 1–15.
</div>
<div id="ref-quinn2011application" class="csl-entry" role="listitem">
Quinn, John E, James R Brandle, Ron J Johnson, and Andrew J Tyre. 2011. <span>“Application of Detectability in the Use of Indicator Species: A Case Study with Birds.”</span> <em>Ecological Indicators</em> 11 (5): 1413–18.
</div>
<div id="ref-shin2015ecological" class="csl-entry" role="listitem">
Shin, Dong-Hee, and Min Jae Choi. 2015. <span>“Ecological Views of Big Data: Perspectives and Issues.”</span> <em>Telematics and Informatics</em> 32 (2): 311–20.
</div>
<div id="ref-stephenson2020inventory" class="csl-entry" role="listitem">
Stephenson, PJ, and Carrie Stengel. 2020. <span>“An Inventory of Biodiversity Data Sources for Conservation Monitoring.”</span> <em>PLoS One</em> 15 (12): e0242923.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>